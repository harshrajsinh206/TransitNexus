# -*- coding: utf-8 -*-
"""P2.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1ZSUAuGLNATYr9P-N-m9wTQp-iYojX05n
"""

import pandas as pd
from sklearn.ensemble import RandomForestRegressor
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import OrdinalEncoder
from sklearn.metrics import r2_score
import pickle

from google.colab import files

# Upload new_ridership_model.pkl from your device
uploaded = files.upload()

!pip install --upgrade scikit-learn --quiet

# Version
import sklearn
print("scikit-learn version:", sklearn.__version__)

!pip install -U scikit-learn --quiet

import pandas as pd
from sklearn.ensemble import RandomForestRegressor
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import OrdinalEncoder
from sklearn.metrics import r2_score

# Simulated dataset
df = pd.DataFrame({
    'station_complex_id': [1, 2, 3, 1, 2, 3]*100,
    'hour': [8, 9, 10, 17, 18, 19]*100,
    'borough': ['Manhattan', 'Brooklyn', 'Queens', 'Manhattan', 'Bronx', 'Staten Island']*100,
    'payment_method': ['OMNY', 'MetroCard', 'OMNY', 'OMNY', 'MetroCard', 'MetroCard']*100,
    'fare_class_category': ['Full', 'Reduced', 'Full', 'Reduced', 'Student', 'Full']*100,
    'ridership': [200, 150, 180, 220, 160, 170]*100
})

# features and target
X = df.drop('ridership', axis=1)
y = df['ridership']

# Encodeing categorical variables
categorical_cols = ['borough', 'payment_method', 'fare_class_category']
encoder = OrdinalEncoder()
X[categorical_cols] = encoder.fit_transform(X[categorical_cols])

# Split and train
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)
model = RandomForestRegressor(n_estimators=100, random_state=42)
model.fit(X_train, y_train)

# Accuracy
y_pred = model.predict(X_test)
print("Model R2 Score:", r2_score(y_test, y_pred))

# Sample input
input_df = pd.DataFrame({
    'station_complex_id': [1],
    'hour': [8],
    'borough': ['Manhattan'],
    'payment_method': ['OMNY'],
    'fare_class_category': ['Full']
})

# Encode categorical input
input_df[categorical_cols] = encoder.transform(input_df[categorical_cols])

# Predict
predicted = model.predict(input_df)[0]
print(f"🎯 Predicted Ridership: {int(predicted)} passengers")

from itertools import combinations
import pandas as pd

# Simulated consistent data
data = pd.DataFrame({
    'station_complex_id': [1, 2, 3]*100,
    'hour': [8, 17, 8, 17, 10, 19]*50,
    'ridership': [200, 200, 180, 220, 190, 170]*50
})

# Step 1: Get average ridership per station per hour
station_hourly = data.groupby(['station_complex_id', 'hour'])['ridership'].mean().reset_index()

# Step 2: Get top 5 most crowded stations overall
top_stations = data.groupby('station_complex_id')['ridership'].sum().sort_values(ascending=False).head(5)
top_ids = top_stations.index.tolist()

print("🚇 Top 5 crowded stations:")
print(top_stations)


pairs = list(combinations(top_ids, 2))
for station1, station2 in pairs:
    s1 = station_hourly[station_hourly['station_complex_id'] == station1].set_index('hour')['ridership']
    s2 = station_hourly[station_hourly['station_complex_id'] == station2].set_index('hour')['ridership']

data = pd.DataFrame({
    'station_complex_id': [1, 2, 3]*100,
    'hour': [8, 17, 8, 17, 10, 19]*50,
    'ridership': [200, 200, 180, 220, 190, 170]*50
})

from google.colab import drive

# Mount Google Drive
drive.mount('/content/drive')

file_path = '/content/drive/MyDrive/MTA/MTA_Subway_Hourly_Ridership__Beginning_February_2022.csv'
df = pd.read_csv(file_path)
df

df = pd.DataFrame({
    'station_complex_id': [1, 2, 3, 1, 2, 3]*100,
    'hour': [8, 9, 10, 17, 18, 19]*100,
    'borough': ['Manhattan', 'Brooklyn', 'Queens', 'Manhattan', 'Bronx', 'Staten Island']*100,
    'payment_method': ['OMNY', 'MetroCard', 'OMNY', 'OMNY', 'MetroCard', 'MetroCard']*100,
    'fare_class_category': ['Full', 'Reduced', 'Full', 'Reduced', 'Student', 'Full']*100,
    'ridership': [200, 150, 180, 220, 160, 170]*100
})

# Preprocessing categorical features
X = df.drop('ridership', axis=1)
y = df['ridership']

categorical_cols = ['borough', 'payment_method', 'fare_class_category']
encoder = OrdinalEncoder()
X[categorical_cols] = encoder.fit_transform(X[categorical_cols])

# Train/test split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Train new model
model = RandomForestRegressor(n_estimators=100, random_state=42)
model.fit(X_train, y_train)

# Evaluate
y_pred = model.predict(X_test)
accuracy = r2_score(y_test, y_pred)

pip install streamlit

!pip install streamlit --quiet
!pip install pyngrok --quiet

# Commented out IPython magic to ensure Python compatibility.
# %%writefile app.py
# import streamlit as st
# import pandas as pd
# import matplotlib.pyplot as plt
# from sklearn.ensemble import RandomForestRegressor
# from sklearn.preprocessing import OrdinalEncoder
# import numpy as np
# import datetime
# 
# st.set_page_config(page_title="NYC Subway Ridership Dashboard", layout="wide")
# st.title("🚇 NYC Subway Insights & Ridership Dashboard")
# 
# # --- Station Data ---
# station_names = {
#     1: "Times Square", 2: "34th St Herald Sq", 3: "14th St Union Sq", 4: "Columbus Circle", 5: "Wall Street",
#     6: "Jay St MetroTech", 7: "Atlantic Ave", 8: "Church Ave", 9: "Crown Heights Utica", 10: "Broadway Junction",
#     11: "Jamaica Center", 12: "Flushing Main St", 13: "Forest Hills 71 Av", 14: "Sutphin Blvd", 15: "Queensboro Plaza",
#     16: "Fordham Rd", 17: "149th St Grand Concourse", 18: "Yankee Stadium", 19: "Burnside Ave", 20: "Pelham Bay Park",
#     21: "St. George", 22: "Tompkinsville", 23: "Stapleton", 24: "Grasmere", 25: "New Dorp"
# }
# 
# station_boroughs = {
#     1: "Manhattan", 2: "Manhattan", 3: "Manhattan", 4: "Manhattan", 5: "Manhattan",
#     6: "Brooklyn", 7: "Brooklyn", 8: "Brooklyn", 9: "Brooklyn", 10: "Brooklyn",
#     11: "Queens", 12: "Queens", 13: "Queens", 14: "Queens", 15: "Queens",
#     16: "Bronx", 17: "Bronx", 18: "Bronx", 19: "Bronx", 20: "Bronx",
#     21: "Staten Island", 22: "Staten Island", 23: "Staten Island", 24: "Staten Island", 25: "Staten Island"
# }
# 
# borough_list = ["Manhattan", "Queens", "Bronx", "Brooklyn", "Staten Island"]
# 
# # --- Generate Synthetic Data ---
# rows = []
# np.random.seed(42)
# for station_id, name in station_names.items():
#     borough = station_boroughs[station_id]
#     for hour in range(6, 22):
#         month = np.random.randint(1, 13)
#         base = np.random.randint(10, 250)
#         if 8 <= hour <= 10 or 16 <= hour <= 19:
#             ridership = base + np.random.randint(60, 2000)
#         elif 6 <= hour <= 7 or 11 <= hour <= 13:
#             ridership = base + np.random.randint(30, 60)
#         else:
#             ridership = base + np.random.randint(0, 30)
#         rows.append({
#             'station_complex_id': station_id,
#             'station_name': name,
#             'borough': borough,
#             'hour': hour,
#             'month': month,
#             'payment_method': 'OMNY',
#             'fare_class_category': 'Full',
#             'ridership': ridership
#         })
# 
# data = pd.DataFrame(rows)
# 
# def month_to_season(month):
#     if month in [12, 1, 2]: return 'Winter'
#     elif month in [3, 4, 5]: return 'Spring'
#     elif month in [6, 7, 8]: return 'Summer'
#     else: return 'Fall'
# 
# data['season'] = data['month'].apply(month_to_season)
# 
# # --- Train Model ---
# categorical_cols = ['borough', 'payment_method', 'fare_class_category']
# encoder = OrdinalEncoder()
# data[categorical_cols] = encoder.fit_transform(data[categorical_cols])
# X = data.drop(['ridership', 'station_name', 'season'], axis=1)
# y = data['ridership']
# model = RandomForestRegressor(n_estimators=100, random_state=42)
# model.fit(X, y)
# 
# # --- Tabs ---
# tabs = st.tabs(["🎯 Predict Ridership", "📊 Trends & Comparisons", "🌤 Seasonal Trends"])
# 
# # --- Tab 1: Prediction ---
# with tabs[0]:
#     st.header("🎯 Predict Subway Ridership")
#     user_borough = st.selectbox("Select Borough", borough_list)
#     user_date = st.date_input("Select Date")
#     user_time = st.time_input("Select Time")
#     hour = user_time.hour
# 
#     station_name_input = st.selectbox("Select Station", [name for id, name in station_names.items() if station_boroughs[id] == user_borough])
#     station_id = [k for k, v in station_names.items() if v == station_name_input][0]
# 
#     user_input = pd.DataFrame({
#         'station_complex_id': [station_id],
#         'hour': [hour],
#         'borough': [user_borough],
#         'payment_method': ['OMNY'],
#         'fare_class_category': ['Full'],
#         'month': [user_date.month]
#     })
#     user_input[categorical_cols] = encoder.transform(user_input[categorical_cols])
#     user_input = user_input[X.columns]
# 
#     if st.button("🔮 Predict Ridership"):
#         prediction = model.predict(user_input)[0]
#         st.success(f"Estimated ridership at {station_name_input}, {user_borough} at {user_time.strftime('%H:%M')} on {user_date.strftime('%Y-%m-%d')} is {int(prediction)} passengers")
# 
#         st.subheader("⏰ Busiest Hour Prediction")
#         hour_preds = []
#         for h in range(6, 22):
#             test_input = pd.DataFrame({
#                 'station_complex_id': [station_id],
#                 'hour': [h],
#                 'borough': [user_borough],
#                 'payment_method': ['OMNY'],
#                 'fare_class_category': ['Full'],
#                 'month': [user_date.month]
#             })
#             test_input[categorical_cols] = encoder.transform(test_input[categorical_cols])
#             test_input = test_input[X.columns]
#             hour_preds.append(model.predict(test_input)[0])
#         busiest_hour = list(range(6, 22))[hour_preds.index(max(hour_preds))]
#         st.write(f"📌 Predicted busiest hour at {station_name_input} is: {busiest_hour}:00")
# 
# # --- Tab 2: Trends ---
# with tabs[1]:
#     st.header("📊 Ridership Trends and Comparisons")
# 
#     st.subheader("🚇 Top 5 Crowded Stations by Borough")
#     selected_borough = st.selectbox("Filter by Borough", borough_list, key='borough_select')
#     encoded_borough = encoder.transform([[selected_borough, 'OMNY', 'Full']])[0][0]
#     filtered_data = data[data['borough'] == encoded_borough]
#     if not filtered_data.empty:
#         top_stations = filtered_data.groupby(['station_complex_id', 'station_name'])['ridership'].sum().sort_values(ascending=False).head(5).reset_index()
#         st.dataframe(top_stations.rename(columns={"ridership": "Total Ridership"}))
#     else:
#         st.warning("No data available for this borough.")
# 
#     st.subheader("📈 Ridership Trends")
#     st.line_chart(filtered_data.groupby('hour')['ridership'].mean())
# 
#     st.subheader("📌 Overall Most Crowded Stations")
#     st.bar_chart(filtered_data.groupby('station_name')['ridership'].sum().sort_values(ascending=False).head(10))
# 
#     st.subheader("📊 Compare Two Stations")
#     station1 = st.selectbox("Station 1", list(station_names.values()), key='s1')
#     station2 = st.selectbox("Station 2", list(station_names.values()), key='s2')
#     comparison = data[data['station_name'].isin([station1, station2])]
#     comp_hour = comparison.groupby(['hour', 'station_name'])['ridership'].mean().unstack()
#     st.line_chart(comp_hour)
# 
#     st.subheader("🕗 Morning vs Evening")
#     data['time_period'] = data['hour'].apply(lambda h: 'Morning' if 6 <= h < 12 else 'Evening' if 16 <= h < 22 else 'Midday')
#     filtered_time = filtered_data.copy()
#     filtered_time['time_period'] = filtered_time['hour'].apply(lambda h: 'Morning' if 6 <= h < 12 else 'Evening' if 16 <= h < 22 else 'Midday')
#     st.bar_chart(filtered_time[filtered_time['time_period'].isin(['Morning', 'Evening'])].groupby(['station_name', 'time_period'])['ridership'].mean().unstack().fillna(0))
# 
# # --- Tab 3: Seasonal Trends ---
# with tabs[2]:
#     st.header("🌤 Seasonal Peak Ridership Analysis")
# 
#     st.subheader("🧭 Total Ridership by Season")
#     st.bar_chart(data.groupby('season')['ridership'].sum().sort_values(ascending=False))
# 
#     st.subheader("🏙️ Top 5 Stations per Season")
#     season_choice = st.selectbox("Choose a Season", ['Winter', 'Spring', 'Summer', 'Fall'])
#     seasonal_df = data[data['season'] == season_choice]
#     top_seasonal = seasonal_df.groupby('station_name')['ridership'].sum().sort_values(ascending=False).head(5)
#     st.bar_chart(top_seasonal)
# 
#

from pyngrok import ngrok


ngrok.set_auth_token("Your_Token")



!pkill streamlit

from pyngrok import ngrok

# Disconnect all active tunnels
ngrok.kill()

# 1. Stop previous tunnels and Streamlit
!pkill streamlit
from pyngrok import ngrok
ngrok.kill()

# 2. Launch Streamlit in background
import threading

def run_app():
    !streamlit run app.py

threading.Thread(target=run_app).start()

# 3. Open new tunnel safely
public_url = ngrok.connect(addr="8501", proto="http")
print(f"\n🌐 Open your Streamlit app here: {public_url}")